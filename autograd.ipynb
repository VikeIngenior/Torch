{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h4>torch.autograd is Pytorch's automatic differentiation engine that powers nn training.</h4>\n",
    "Note: The stuff done in this notebook will work only on the CPU and won't work on GPU devices."
   ],
   "id": "b58d4d92fca44bc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:28:36.631178Z",
     "start_time": "2024-11-04T20:28:30.609239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Pretrained model 'ResNet18' will be loaded.\n",
    "A random data tensor presenting an image with 3 channels will be created\n",
    "Its label will be initialized to random values\n",
    "Note: Label in pretrained models has shape (1,1000)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ],
   "id": "b9fd75181c1030bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\kyse1/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:28:51.198375Z",
     "start_time": "2024-11-04T20:28:51.192176Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "35c3ca8f14598b88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:28:59.057497Z",
     "start_time": "2024-11-04T20:28:59.049850Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "6da8f650561ed799",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2117, 0.5543, 0.9860,  ..., 0.7252, 0.4199, 0.1249],\n",
       "          [0.1111, 0.9561, 0.2540,  ..., 0.3054, 0.3626, 0.7873],\n",
       "          [0.7984, 0.8573, 0.9884,  ..., 0.1853, 0.2349, 0.4863],\n",
       "          ...,\n",
       "          [0.5683, 0.6763, 0.8860,  ..., 0.2888, 0.8374, 0.0172],\n",
       "          [0.3904, 0.8462, 0.4567,  ..., 0.4410, 0.7195, 0.6702],\n",
       "          [0.3197, 0.9499, 0.9307,  ..., 0.1056, 0.7432, 0.1767]],\n",
       "\n",
       "         [[0.3033, 0.7592, 0.4992,  ..., 0.9840, 0.1519, 0.0893],\n",
       "          [0.8509, 0.8755, 0.8676,  ..., 0.9440, 0.2599, 0.4061],\n",
       "          [0.2671, 0.9063, 0.4324,  ..., 0.4271, 0.0232, 0.8376],\n",
       "          ...,\n",
       "          [0.6181, 0.1994, 0.5076,  ..., 0.8251, 0.9532, 0.4044],\n",
       "          [0.0194, 0.5830, 0.4186,  ..., 0.3481, 0.6644, 0.5034],\n",
       "          [0.1284, 0.0809, 0.5181,  ..., 0.7996, 0.6881, 0.4045]],\n",
       "\n",
       "         [[0.3761, 0.6164, 0.7629,  ..., 0.7560, 0.1402, 0.5244],\n",
       "          [0.5427, 0.5400, 0.9914,  ..., 0.4850, 0.2918, 0.2418],\n",
       "          [0.8186, 0.1123, 0.5283,  ..., 0.7099, 0.5324, 0.5643],\n",
       "          ...,\n",
       "          [0.8566, 0.4809, 0.7717,  ..., 0.7591, 0.8185, 0.1080],\n",
       "          [0.5125, 0.7176, 0.3506,  ..., 0.0704, 0.6960, 0.4432],\n",
       "          [0.3139, 0.5492, 0.8196,  ..., 0.8757, 0.4833, 0.0785]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:29:07.168772Z",
     "start_time": "2024-11-04T20:29:07.159704Z"
    }
   },
   "cell_type": "code",
   "source": "labels",
   "id": "9b126541b84377a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9103, 0.5827, 0.3281, 0.9176, 0.0942, 0.7976, 0.6474, 0.3580, 0.4611,\n",
       "         0.4489, 0.2196, 0.7552, 0.1393, 0.3464, 0.0439, 0.9813, 0.7965, 0.0831,\n",
       "         0.6596, 0.8187, 0.4120, 0.9241, 0.7272, 0.7154, 0.5381, 0.1474, 0.1309,\n",
       "         0.5559, 0.0474, 0.0157, 0.1930, 0.8957, 0.8393, 0.8029, 0.8446, 0.1859,\n",
       "         0.4702, 0.7659, 0.3644, 0.9375, 0.3364, 0.4843, 0.1862, 0.2054, 0.9987,\n",
       "         0.5101, 0.2509, 0.8099, 0.1266, 0.1096, 0.6033, 0.4787, 0.5501, 0.2900,\n",
       "         0.8968, 0.7278, 0.5287, 0.3575, 0.4245, 0.5874, 0.5568, 0.5213, 0.6846,\n",
       "         0.0799, 0.8432, 0.6071, 0.6500, 0.9375, 0.4400, 0.4011, 0.2986, 0.8677,\n",
       "         0.7065, 0.4443, 0.0424, 0.5432, 0.0328, 0.8372, 0.3691, 0.1141, 0.3408,\n",
       "         0.7881, 0.6739, 0.5589, 0.5244, 0.8985, 0.5341, 0.2660, 0.2945, 0.2176,\n",
       "         0.6634, 0.2643, 0.4205, 0.2053, 0.8530, 0.1416, 0.7663, 0.5845, 0.8666,\n",
       "         0.0524, 0.4315, 0.9919, 0.8921, 0.9445, 0.9686, 0.4712, 0.5403, 0.6039,\n",
       "         0.7016, 0.8838, 0.3958, 0.6202, 0.7178, 0.4228, 0.0256, 0.1764, 0.5127,\n",
       "         0.7627, 0.9865, 0.7980, 0.6821, 0.1495, 0.1969, 0.3112, 0.0406, 0.8325,\n",
       "         0.3721, 0.7536, 0.8881, 0.5707, 0.0206, 0.9303, 0.9784, 0.9604, 0.1430,\n",
       "         0.5653, 0.6560, 0.5820, 0.8013, 0.3414, 0.8735, 0.3148, 0.8484, 0.9354,\n",
       "         0.5116, 0.0507, 0.5767, 0.3652, 0.8147, 0.4982, 0.6907, 0.4354, 0.8651,\n",
       "         0.7860, 0.9553, 0.7684, 0.4985, 0.9674, 0.9445, 0.9719, 0.3666, 0.3511,\n",
       "         0.6228, 0.4922, 0.9827, 0.3389, 0.0019, 0.5635, 0.1842, 0.7909, 0.0750,\n",
       "         0.0443, 0.7832, 0.5906, 0.3207, 0.9289, 0.2883, 0.9924, 0.0308, 0.1169,\n",
       "         0.3822, 0.1096, 0.5303, 0.7850, 0.8157, 0.6617, 0.8737, 0.7634, 0.5014,\n",
       "         0.9810, 0.5781, 0.5612, 0.0528, 0.8973, 0.6869, 0.9345, 0.8767, 0.8893,\n",
       "         0.0616, 0.6742, 0.1791, 0.8506, 0.5611, 0.2233, 0.8226, 0.9610, 0.0253,\n",
       "         0.3943, 0.6050, 0.5568, 0.9490, 0.2181, 0.8289, 0.6268, 0.4897, 0.9054,\n",
       "         0.0913, 0.1687, 0.7633, 0.9622, 0.5434, 0.8015, 0.2422, 0.7512, 0.7551,\n",
       "         0.9177, 0.9300, 0.2622, 0.6072, 0.4060, 0.1008, 0.0367, 0.8653, 0.9219,\n",
       "         0.2815, 0.1733, 0.7334, 0.5972, 0.4681, 0.7687, 0.8670, 0.6554, 0.1351,\n",
       "         0.9501, 0.6379, 0.8245, 0.5747, 0.1734, 0.0216, 0.9532, 0.1327, 0.4996,\n",
       "         0.6539, 0.4551, 0.8655, 0.7637, 0.8618, 0.9308, 0.8779, 0.6845, 0.8541,\n",
       "         0.8774, 0.7077, 0.1686, 0.8093, 0.1649, 0.4185, 0.9570, 0.0949, 0.4905,\n",
       "         0.0080, 0.9664, 0.8123, 0.5471, 0.0038, 0.4631, 0.2506, 0.4424, 0.9416,\n",
       "         0.1105, 0.7245, 0.1483, 0.1039, 0.1662, 0.8034, 0.5883, 0.9363, 0.8989,\n",
       "         0.3855, 0.8155, 0.0586, 0.4369, 0.3712, 0.4269, 0.0569, 0.5730, 0.9136,\n",
       "         0.7044, 0.6912, 0.0639, 0.4335, 0.1806, 0.2440, 0.6677, 0.6739, 0.1635,\n",
       "         0.5485, 0.5542, 0.0058, 0.1253, 0.4262, 0.7939, 0.3287, 0.1780, 0.7618,\n",
       "         0.1570, 0.7963, 0.7569, 0.8641, 0.8804, 0.9507, 0.4398, 0.0970, 0.1414,\n",
       "         0.1278, 0.8668, 0.7130, 0.7124, 0.7246, 0.3454, 0.5814, 0.2001, 0.0540,\n",
       "         0.3141, 0.4275, 0.7454, 0.4974, 0.5798, 0.9220, 0.3305, 0.6620, 0.3267,\n",
       "         0.9483, 0.1677, 0.9334, 0.8824, 0.3251, 0.5315, 0.1495, 0.7752, 0.4159,\n",
       "         0.7892, 0.1082, 0.3243, 0.2268, 0.6649, 0.0125, 0.3564, 0.2792, 0.9845,\n",
       "         0.2197, 0.4577, 0.8595, 0.4483, 0.9885, 0.7141, 0.7390, 0.3273, 0.1081,\n",
       "         0.9483, 0.9767, 0.2673, 0.1863, 0.9393, 0.3512, 0.1674, 0.4630, 0.2697,\n",
       "         0.1222, 0.6601, 0.0479, 0.8489, 0.9991, 0.1908, 0.8416, 0.3503, 0.5630,\n",
       "         0.8231, 0.4806, 0.3254, 0.8912, 0.8259, 0.9368, 0.5952, 0.0946, 0.2886,\n",
       "         0.8165, 0.6970, 0.2034, 0.9903, 0.0642, 0.9967, 0.5147, 0.8605, 0.4665,\n",
       "         0.1424, 0.3595, 0.1644, 0.4378, 0.6518, 0.2347, 0.4388, 0.9091, 0.5707,\n",
       "         0.9960, 0.8019, 0.6646, 0.7430, 0.3228, 0.8841, 0.3856, 0.8622, 0.6127,\n",
       "         0.7794, 0.6226, 0.6233, 0.8189, 0.8617, 0.5596, 0.1898, 0.3989, 0.7417,\n",
       "         0.2882, 0.5841, 0.8392, 0.5594, 0.1543, 0.9258, 0.6987, 0.3270, 0.0299,\n",
       "         0.1273, 0.8520, 0.1266, 0.5294, 0.4205, 0.2012, 0.1023, 0.0781, 0.8510,\n",
       "         0.1407, 0.3064, 0.7161, 0.6415, 0.8102, 0.9008, 0.6590, 0.3655, 0.5130,\n",
       "         0.5240, 0.0913, 0.8676, 0.7530, 0.4333, 0.3609, 0.2182, 0.8246, 0.6487,\n",
       "         0.8352, 0.5309, 0.8254, 0.1816, 0.7116, 0.0777, 0.8423, 0.0632, 0.6207,\n",
       "         0.6222, 0.7563, 0.6381, 0.4270, 0.5553, 0.7887, 0.6459, 0.6597, 0.5416,\n",
       "         0.7196, 0.1690, 0.4632, 0.8607, 0.0307, 0.9111, 0.3813, 0.2078, 0.1468,\n",
       "         0.1903, 0.8874, 0.1067, 0.8673, 0.9022, 0.9885, 0.5833, 0.9534, 0.6454,\n",
       "         0.8288, 0.1789, 0.7476, 0.1308, 0.9508, 0.0713, 0.1209, 0.7887, 0.1692,\n",
       "         0.2802, 0.5478, 0.1423, 0.6394, 0.5144, 0.4225, 0.2377, 0.0875, 0.2063,\n",
       "         0.1975, 0.4111, 0.0938, 0.1156, 0.1092, 0.3232, 0.3357, 0.5525, 0.9691,\n",
       "         0.1693, 0.9814, 0.3418, 0.6278, 0.9456, 0.9596, 0.2960, 0.5526, 0.6899,\n",
       "         0.6597, 0.3530, 0.4766, 0.9766, 0.5669, 0.8235, 0.1069, 0.1904, 0.5722,\n",
       "         0.3970, 0.8691, 0.9603, 0.8051, 0.7804, 0.1967, 0.5640, 0.9295, 0.3395,\n",
       "         0.8662, 0.8748, 0.1896, 0.2944, 0.5459, 0.5663, 0.0806, 0.5714, 0.3748,\n",
       "         0.4058, 0.3636, 0.0239, 0.0749, 0.7074, 0.6004, 0.3117, 0.1267, 0.9041,\n",
       "         0.9202, 0.1840, 0.8014, 0.9465, 0.8603, 0.4188, 0.7926, 0.5446, 0.9592,\n",
       "         0.1031, 0.3640, 0.5442, 0.3548, 0.7008, 0.2602, 0.7571, 0.9340, 0.3845,\n",
       "         0.7858, 0.9847, 0.2874, 0.9458, 0.2832, 0.2160, 0.9305, 0.9099, 0.8012,\n",
       "         0.3006, 0.8395, 0.2465, 0.6468, 0.9309, 0.4660, 0.2198, 0.4724, 0.4162,\n",
       "         0.6641, 0.1336, 0.5165, 0.3635, 0.7919, 0.6267, 0.6817, 0.1201, 0.3332,\n",
       "         0.6156, 0.8415, 0.4980, 0.0107, 0.2603, 0.3935, 0.8384, 0.4232, 0.1436,\n",
       "         0.1851, 0.2288, 0.8998, 0.6114, 0.9664, 0.6791, 0.1802, 0.8564, 0.1548,\n",
       "         0.1517, 0.1100, 0.5289, 0.5160, 0.5783, 0.2135, 0.2258, 0.9747, 0.1425,\n",
       "         0.5670, 0.6258, 0.1831, 0.4730, 0.2614, 0.5770, 0.3167, 0.5959, 0.5433,\n",
       "         0.7662, 0.9382, 0.4177, 0.1073, 0.6331, 0.9645, 0.4704, 0.5136, 0.2258,\n",
       "         0.7683, 0.0457, 0.5132, 0.7932, 0.1126, 0.5364, 0.7084, 0.6067, 0.5315,\n",
       "         0.9095, 0.9102, 0.0416, 0.0397, 0.6484, 0.5462, 0.2009, 0.4180, 0.9111,\n",
       "         0.2289, 0.1590, 0.2030, 0.7610, 0.8951, 0.2799, 0.6705, 0.1200, 0.5427,\n",
       "         0.8692, 0.4197, 0.5560, 0.4701, 0.6310, 0.4407, 0.8820, 0.9923, 0.6397,\n",
       "         0.6746, 0.9065, 0.4651, 0.5234, 0.8995, 0.4322, 0.2670, 0.2684, 0.2675,\n",
       "         0.1424, 0.3448, 0.1547, 0.6203, 0.8904, 0.4681, 0.2010, 0.1347, 0.4284,\n",
       "         0.9424, 0.4155, 0.0934, 0.3382, 0.5084, 0.5616, 0.1216, 0.0319, 0.9123,\n",
       "         0.0145, 0.2103, 0.5879, 0.1435, 0.8046, 0.5692, 0.8629, 0.6880, 0.2123,\n",
       "         0.7757, 0.1072, 0.3796, 0.7049, 0.0136, 0.1607, 0.5742, 0.9723, 0.5937,\n",
       "         0.3480, 0.8321, 0.8631, 0.2861, 0.4094, 0.5054, 0.4551, 0.7407, 0.0290,\n",
       "         0.8294, 0.7325, 0.7300, 0.1713, 0.5424, 0.9752, 0.0846, 0.7746, 0.7085,\n",
       "         0.6702, 0.6680, 0.8185, 0.4774, 0.5217, 0.5256, 0.8523, 0.5590, 0.6819,\n",
       "         0.2837, 0.6132, 0.5130, 0.6569, 0.5019, 0.1333, 0.5416, 0.5744, 0.4654,\n",
       "         0.9381, 0.7615, 0.9146, 0.2827, 0.2353, 0.2457, 0.4537, 0.5533, 0.6848,\n",
       "         0.6861, 0.1030, 0.8524, 0.3447, 0.8264, 0.5640, 0.0964, 0.5767, 0.2172,\n",
       "         0.0934, 0.7152, 0.7604, 0.7250, 0.6606, 0.4160, 0.8337, 0.7615, 0.1340,\n",
       "         0.3522, 0.1049, 0.6100, 0.8233, 0.1879, 0.3983, 0.9470, 0.3769, 0.7718,\n",
       "         0.0685, 0.4563, 0.9286, 0.9390, 0.7561, 0.1176, 0.0438, 0.1114, 0.4932,\n",
       "         0.8656, 0.1733, 0.7586, 0.7864, 0.2690, 0.6223, 0.2291, 0.4763, 0.7594,\n",
       "         0.6441, 0.6037, 0.5870, 0.6275, 0.8608, 0.5191, 0.8182, 0.2076, 0.3768,\n",
       "         0.2520, 0.4161, 0.7947, 0.3419, 0.1003, 0.7795, 0.2693, 0.1688, 0.9680,\n",
       "         0.0778, 0.4455, 0.5721, 0.7315, 0.3489, 0.0926, 0.7688, 0.3376, 0.1855,\n",
       "         0.9173, 0.0541, 0.3001, 0.0656, 0.2850, 0.4281, 0.2405, 0.5333, 0.0894,\n",
       "         0.4140, 0.9548, 0.4890, 0.7588, 0.0728, 0.0832, 0.0111, 0.2169, 0.4536,\n",
       "         0.2232, 0.4161, 0.3351, 0.9015, 0.0049, 0.8235, 0.4509, 0.3147, 0.4738,\n",
       "         0.8923, 0.1226, 0.0768, 0.3697, 0.2039, 0.9749, 0.2784, 0.9861, 0.7517,\n",
       "         0.4650, 0.7779, 0.0375, 0.2907, 0.4361, 0.0178, 0.4608, 0.0074, 0.2572,\n",
       "         0.1513, 0.4181, 0.0028, 0.2635, 0.2193, 0.8542, 0.3837, 0.7523, 0.8875,\n",
       "         0.7458, 0.1546, 0.4941, 0.3264, 0.9179, 0.9543, 0.1209, 0.0895, 0.4191,\n",
       "         0.0148, 0.8094, 0.0566, 0.1920, 0.2965, 0.2115, 0.5991, 0.8221, 0.5355,\n",
       "         0.0743, 0.2274, 0.3537, 0.2799, 0.3098, 0.2215, 0.0621, 0.9280, 0.8856,\n",
       "         0.8668, 0.7088, 0.8009, 0.1081, 0.1083, 0.3713, 0.3315, 0.4661, 0.6769,\n",
       "         0.2121, 0.9622, 0.2255, 0.9129, 0.9209, 0.8723, 0.9792, 0.0274, 0.0197,\n",
       "         0.8618, 0.6950, 0.6248, 0.0057, 0.8320, 0.6636, 0.1231, 0.9224, 0.2318,\n",
       "         0.7084, 0.7954, 0.8082, 0.3303, 0.2152, 0.8812, 0.6130, 0.7618, 0.7644,\n",
       "         0.0903, 0.5307, 0.6960, 0.2994, 0.9688, 0.7242, 0.2760, 0.6812, 0.8778,\n",
       "         0.1388, 0.0457, 0.8998, 0.4032, 0.8447, 0.2999, 0.5452, 0.9291, 0.9595,\n",
       "         0.0749]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:30:00.220801Z",
     "start_time": "2024-11-04T20:30:00.153285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Running the data through the model. \n",
    "prediction = model(data) # Forward"
   ],
   "id": "3cc47335cb044049",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:30:02.590490Z",
     "start_time": "2024-11-04T20:30:02.580222Z"
    }
   },
   "cell_type": "code",
   "source": "prediction",
   "id": "acad907ae9714f94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3340, -0.3251, -0.3337, -1.4205, -0.4836,  0.0316, -0.3429,  0.8390,\n",
       "          0.6336, -0.5129, -0.8618, -0.8016, -0.4476, -0.8705, -1.1114, -0.3287,\n",
       "         -0.8865, -0.2240, -0.0344, -0.6132, -1.4345, -0.3658, -1.1085,  0.6282,\n",
       "         -0.6967, -1.0995, -0.7047, -1.1743, -0.8698, -0.2256, -0.4846, -0.6727,\n",
       "         -0.3551, -0.6691, -0.3513, -0.4912,  0.6421, -0.8465, -0.5512,  0.2823,\n",
       "         -0.6742, -0.7810, -1.1979, -0.1570, -0.7531, -0.5526, -0.7830, -0.1931,\n",
       "         -1.0609, -0.8086, -0.2225,  0.3904, -0.4159, -0.7328, -0.0992, -1.0215,\n",
       "         -0.3966, -1.4470, -0.4947, -0.4091,  0.7632, -0.0052,  0.0652,  0.4079,\n",
       "         -0.5526, -0.0791, -0.2292, -0.2164, -0.7383, -1.0964, -1.5240,  0.1300,\n",
       "         -1.2628, -0.2270, -1.1127, -1.2977, -0.3154, -0.6963,  0.1692,  0.1453,\n",
       "         -0.4542, -1.2775,  0.2216, -0.4617, -0.1862,  0.0516,  0.1729,  0.4919,\n",
       "          0.1123, -0.3221, -1.1843, -0.9452, -1.8720, -0.1097,  0.3717, -1.9346,\n",
       "         -0.5536, -0.1963, -1.3935,  0.1842, -0.8785, -1.0211, -0.9675,  0.0259,\n",
       "          0.2516, -0.5403, -0.1622, -1.2663, -0.8331, -1.4647, -0.7888, -0.5203,\n",
       "          1.0932,  0.1062,  0.4216, -0.8367, -0.8263, -0.2138,  0.4723, -0.4640,\n",
       "         -0.6959,  0.0107,  0.6661,  0.2687,  1.1330, -0.2134,  0.2925, -1.1829,\n",
       "         -0.9433, -0.9155, -1.1658, -1.2364, -0.6417, -1.1981, -0.4623, -1.1415,\n",
       "         -0.7839, -1.0506, -1.1290, -1.4303, -1.7474, -1.8281, -2.2623, -1.4095,\n",
       "         -0.3263, -0.2216, -0.8350, -1.6585, -1.0946, -1.0008,  0.7210,  1.5191,\n",
       "         -0.8609, -0.2987, -0.0851,  0.1950, -0.4230, -0.0500,  0.3821,  0.2216,\n",
       "          0.6397,  0.7855,  0.3460,  0.6862,  0.3461, -0.0094, -0.0405, -0.4287,\n",
       "          0.4043, -0.0843, -0.1749,  0.8130,  0.5742,  0.3992,  0.1426, -0.6972,\n",
       "          0.2766,  0.0143,  0.4548,  0.8758,  0.8845, -0.1380,  0.3427,  0.0283,\n",
       "          0.4112,  0.6082,  0.5604,  0.1898, -0.0088,  0.4158, -0.5681,  0.3039,\n",
       "          0.1643,  0.6409, -0.9110,  0.7735, -0.2080,  0.1066,  0.1970,  0.5667,\n",
       "          0.1690,  0.3394,  0.3374,  0.3913,  0.0769,  0.5098,  0.0937,  0.3914,\n",
       "          1.4069,  0.4185, -0.0070,  0.3782,  0.5707, -0.0143,  0.0835,  0.4041,\n",
       "         -0.1514,  0.5240, -0.3124,  0.4618,  0.1839, -0.1115, -0.0156,  0.6546,\n",
       "          0.3858,  0.3005,  0.3539,  0.8054, -0.5155, -0.0325,  0.0561,  0.5849,\n",
       "          0.5207, -0.2851,  0.9476,  0.9830,  0.6165,  0.3526,  0.8885, -0.1871,\n",
       "          0.5171, -0.0956,  0.5712,  0.4095, -0.3709,  0.4404,  0.7314,  0.1083,\n",
       "          0.7655,  0.1322,  0.4278,  0.6405, -1.0090,  0.8489,  0.7944, -0.7979,\n",
       "          0.4084,  0.2256, -0.1487,  0.1931, -0.2579, -0.7582, -0.4789,  0.3583,\n",
       "          0.8198,  0.6620,  0.0986,  0.6400, -0.1196, -0.1735, -0.8051, -0.9133,\n",
       "         -0.6441,  0.5701, -1.2433, -1.0900, -1.0479, -0.8235, -1.1710, -0.4833,\n",
       "         -0.2066,  1.0457,  1.0728, -0.1350,  0.1107,  0.9740, -0.3867, -0.4704,\n",
       "         -0.7155, -1.5238, -0.9496, -1.1989, -0.1655, -1.2477, -0.8159, -0.6346,\n",
       "         -0.7585, -0.9068, -0.2069, -0.1122, -1.8557, -0.7393, -0.4296, -0.4721,\n",
       "         -1.1761, -0.8852,  0.0522, -0.9629, -1.3100, -0.4917,  0.4540, -0.4758,\n",
       "         -0.2588,  0.1094,  0.4990, -0.3696, -0.8154, -0.9454, -1.1247, -0.7818,\n",
       "         -1.6666, -1.1210, -1.4783, -1.5452, -1.3935, -1.6306, -1.4551, -0.0303,\n",
       "         -0.2192, -0.4576,  0.0844,  0.0235, -0.0265,  0.4339, -0.1767, -0.5860,\n",
       "         -1.4877,  0.5648,  1.0184, -0.9771, -0.2587,  1.0872, -0.1488, -1.2577,\n",
       "         -0.3568,  0.7597, -0.7345, -1.6847, -0.3065, -1.5547, -1.3046, -2.4081,\n",
       "         -1.6919, -0.8688, -0.8391,  0.2995,  1.4326,  0.2576,  0.7698,  0.7811,\n",
       "          0.0494,  0.7909,  0.1811,  0.2018, -0.3137, -0.3365, -0.9884, -0.2871,\n",
       "         -0.6349, -0.4089, -0.3740, -0.2266, -0.0825, -0.1004, -0.2363, -0.7463,\n",
       "         -1.2309,  0.5731, -0.1885, -0.1694,  0.5003, -0.1467, -0.0486, -0.4976,\n",
       "         -0.6465, -0.5149, -1.1378, -1.0203, -0.8654, -0.0520,  0.8740,  0.1294,\n",
       "         -1.2484, -1.6693, -0.0686,  0.8062, -0.8334, -0.5247,  0.2273, -0.0572,\n",
       "         -0.7637,  1.0466, -0.0310, -2.1601, -1.7916, -0.4525, -0.4174, -0.6141,\n",
       "         -0.2916,  0.9471, -0.1911,  0.3330,  1.9567,  0.6777,  0.2726,  1.0078,\n",
       "         -0.1455,  0.1268,  0.3194,  0.8015,  0.6105,  1.1731, -0.0171, -0.1939,\n",
       "         -0.2065, -0.9778, -0.0251,  1.4593,  2.0932,  0.5431, -0.7442, -0.1728,\n",
       "          0.3332,  0.6132,  0.6524,  1.1020, -0.5995, -0.2295,  0.5736,  0.5329,\n",
       "          1.0749,  0.6972, -0.0584, -0.5921, -0.1861,  0.2667,  0.3104,  1.3144,\n",
       "          0.6672, -0.9789,  0.0146,  0.4257,  0.5448, -0.3465, -0.4511,  0.3679,\n",
       "          1.5795,  1.3113, -0.1687,  0.6923, -0.7515,  0.5270,  1.1424,  2.6180,\n",
       "          1.0130, -0.4168, -1.2802, -0.1582, -0.2132,  1.7956,  1.2187,  0.6494,\n",
       "          0.1923,  0.9238, -0.2910,  0.0637,  0.0163,  0.3172,  0.6446,  0.2747,\n",
       "         -0.0794,  0.0641,  0.3190, -1.0214, -1.5039, -0.2016, -0.3445,  1.0850,\n",
       "          1.4245,  1.1721,  0.6381,  1.0186,  0.4150, -1.3590,  0.9222, -1.2737,\n",
       "          0.1688, -0.6965, -0.3011,  1.3603, -1.7067,  0.5971,  1.1947,  0.5456,\n",
       "          1.0443,  1.1490,  1.1311,  0.4142,  0.3131,  0.2505, -1.2447, -1.0246,\n",
       "          0.5762,  0.2817,  0.9300,  1.8627,  0.1686, -0.1016,  1.4291,  0.5737,\n",
       "         -0.9551,  0.4496,  0.8969,  1.6716,  0.2263, -0.8232, -0.6550, -0.7776,\n",
       "          0.0110,  0.0321,  0.7632,  0.0917, -0.0789, -0.6573,  0.4441, -0.6213,\n",
       "         -0.5313, -0.6817, -0.2522,  1.3806, -1.3226,  1.5641,  1.3838,  0.8152,\n",
       "          0.7063,  0.5752,  0.4449, -2.2098, -1.4120, -0.2381, -0.5672, -0.3444,\n",
       "          0.4215, -0.2767, -1.3062, -0.7823,  0.2900,  0.2119,  1.4834,  1.0754,\n",
       "          0.3611, -0.2862,  1.0752,  0.1201, -1.4738, -0.8773,  0.2567,  1.1178,\n",
       "          0.4764, -0.6020,  0.9618, -0.0361,  1.0122, -0.5975,  0.4265, -0.2622,\n",
       "         -1.0604,  0.8722,  0.3275,  0.0461,  0.1358, -0.4329,  0.8266,  0.2834,\n",
       "          1.3147,  0.9844, -0.7218,  1.6646,  1.0835,  1.1744, -0.8291,  0.3847,\n",
       "         -0.8594,  0.9532,  0.5284, -0.6491,  1.0380, -0.2200, -0.7603,  0.5379,\n",
       "          2.2473, -0.0942,  0.1185, -0.3863,  0.2997,  0.0297,  1.1307, -0.2309,\n",
       "          0.5369, -0.7081,  1.0295,  0.1977, -0.4608,  0.5974, -0.0117,  0.3175,\n",
       "          1.0830,  0.5757,  1.9254,  0.6351,  0.8266,  0.6937,  0.2860,  0.6839,\n",
       "         -0.1932, -1.3347,  0.8739, -0.5867, -1.1898,  0.3357, -0.1904,  0.9143,\n",
       "          0.4754,  0.8455, -0.3837,  0.0311,  1.0685,  0.9606,  0.7525,  0.2126,\n",
       "         -1.8966,  1.2433, -0.0381,  1.3710,  0.9020, -0.6927,  0.7881,  0.4463,\n",
       "         -0.9666, -1.4754,  1.0494,  0.2998,  0.5173,  0.8414, -0.3410,  0.6678,\n",
       "         -0.1751,  0.2242,  0.1600,  0.6015, -0.2740, -1.1804, -0.0890, -1.0951,\n",
       "          0.5912, -0.0343,  1.3930,  0.3389, -1.0786, -0.6311,  0.2120, -0.1567,\n",
       "         -0.6425,  0.3230,  1.5137, -0.9931,  1.6925,  1.0125,  0.9256,  0.1125,\n",
       "          0.4839,  0.3047, -0.7784,  0.3387,  1.0113, -1.5088, -0.2249, -1.2171,\n",
       "         -0.5398, -0.7506, -0.7571,  0.7662,  1.0625,  0.7072, -0.7602,  0.6943,\n",
       "          1.4587, -0.1037, -0.5262,  0.7767,  1.9698, -0.3800,  0.1038,  0.5402,\n",
       "          0.6756, -0.5399, -0.5327,  0.2768,  0.8272,  0.0663,  0.6561,  1.1420,\n",
       "          0.0648, -0.6221,  0.3732, -0.3211,  0.7249, -0.9218, -0.5082,  0.6184,\n",
       "          0.1959,  0.2159,  1.2289,  0.0878, -0.7790,  1.5065, -0.7288, -0.3180,\n",
       "          1.8351, -0.3630,  0.1173,  2.2820, -0.8595,  1.7364, -1.6116,  0.2289,\n",
       "         -0.4691,  0.7519,  0.7977,  0.1631,  1.2016, -0.2708,  0.3178,  0.1526,\n",
       "          0.8609, -0.3418,  0.1577,  0.6559,  0.5787,  1.4667,  0.5286,  0.1199,\n",
       "         -0.1425,  0.3562,  0.5641, -0.7189,  1.0983, -0.0517,  1.3200, -0.3187,\n",
       "          0.1257,  0.6613,  0.5009,  0.4919,  0.9744,  0.7815,  0.7581,  0.4148,\n",
       "         -0.0291,  1.2289,  0.6445, -0.0974,  1.3967,  0.6304,  0.6087,  0.4261,\n",
       "          0.4337,  0.8336,  1.0905, -0.9328, -1.1149, -0.9915,  0.7813,  0.7042,\n",
       "          1.6639,  0.2751,  0.0321,  1.2399, -0.0652, -0.2039,  0.7770,  1.0489,\n",
       "          1.5917,  0.8721,  0.1962,  0.2509,  0.9576,  0.5907, -0.8256,  0.2251,\n",
       "         -1.1280,  0.1495, -1.1900, -1.5671,  1.2825,  1.5076,  0.3647,  0.3778,\n",
       "          1.6085,  0.3966, -0.7843,  1.0826, -0.3257,  1.8255, -0.8055, -0.1659,\n",
       "          0.3914, -0.9397,  1.1646,  0.0138, -1.6020, -1.0002,  0.4964,  0.5832,\n",
       "          0.8817, -1.1546,  0.1842,  0.9677,  1.2276, -0.9437,  0.8989,  0.1668,\n",
       "         -0.6694, -0.8376, -0.0910,  0.6759,  1.6152,  1.6669,  1.3485, -0.7596,\n",
       "          1.3186,  0.5125,  0.6485,  0.6710,  0.5641,  1.5496,  0.5738, -0.5392,\n",
       "          0.4572,  0.8291,  1.1351,  1.4429,  1.7052, -0.6624, -0.6529,  0.6809,\n",
       "         -0.4904, -0.3218, -0.5595,  1.0265,  0.2538,  1.0139,  0.9900, -0.2214,\n",
       "         -0.4550,  0.3958, -0.1510, -0.5268,  1.3023, -0.5319,  1.1210, -1.4770,\n",
       "          0.8310, -1.4198, -2.6642,  0.3220,  1.5541, -0.3768, -0.4793,  1.6356,\n",
       "          0.9404, -0.2203,  0.9459,  1.4856, -0.1054,  0.3722, -0.4784, -0.1911,\n",
       "         -1.4809,  0.1693, -0.0263,  0.0665,  0.6562,  0.0609, -0.9920, -0.5825,\n",
       "          1.0326,  0.4200,  2.0266,  1.9694, -1.3199, -0.3962,  1.6901,  0.8305,\n",
       "          0.8780,  0.0190, -0.5837,  1.4630, -0.8206,  1.2589,  1.1544,  0.8751,\n",
       "          1.0870, -0.5569, -1.8998, -0.6813,  0.0047,  0.2605,  0.6093,  0.2052,\n",
       "         -0.3989,  1.2068, -0.7304,  0.7047, -0.0645, -0.8073, -0.8419, -0.5063,\n",
       "          0.0606,  1.8950,  0.0629,  0.0855,  0.5961, -1.4088,  0.3946, -0.2444,\n",
       "          0.4478,  0.5454,  0.0892,  0.1427, -0.1310, -0.6864, -0.1804,  0.3296,\n",
       "         -0.5884, -0.3608, -1.2607,  0.2879,  0.6086, -0.4184, -0.0126, -0.4434,\n",
       "         -0.7237,  0.5228,  0.5929, -0.4206, -0.3148, -0.7351, -0.0312, -0.6565,\n",
       "          0.2619,  0.3597, -0.3153, -0.7020, -1.2265,  0.0996,  0.6275, -0.7323,\n",
       "          0.8488,  0.1359, -0.1401,  1.1295, -0.6049, -0.4374, -1.8574,  0.8869,\n",
       "         -1.8287,  0.4491,  0.0868, -1.0965, -0.6128,  0.1427,  0.5275, -0.5066,\n",
       "         -0.9005, -0.9954, -2.2464,  1.5454, -0.4665, -0.9473, -0.5939, -1.0858,\n",
       "         -0.8978, -1.7813, -0.6274, -0.5810, -0.0814, -0.5804,  1.4144,  0.8551]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:35:15.154675Z",
     "start_time": "2024-11-04T20:35:15.143170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, the prediction and the labels are used to calculate the error. \n",
    "# This error will be backpropagated.\n",
    "# Then autograd will calculate and store the gradients for each model parameter in the parameter's '.grad' attribute\n",
    "\n",
    "loss = (prediction - labels).sum()\n",
    "loss"
   ],
   "id": "9d02be116f3e91e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-516.5287, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:35:27.723312Z",
     "start_time": "2024-11-04T20:35:27.616161Z"
    }
   },
   "cell_type": "code",
   "source": "loss.backward()",
   "id": "ec8dbdcf62c2b371",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:37:15.823152Z",
     "start_time": "2024-11-04T20:37:15.819153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# An optimizer will be loaded. All the parameters of the model will be registered to the optimizer.\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9) # 1e-2 = 0.01"
   ],
   "id": "531f8cacb9fdc46f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:37:33.095436Z",
     "start_time": "2024-11-04T20:37:33.072040Z"
    }
   },
   "cell_type": "code",
   "source": "optim.step() #gradient descent",
   "id": "b5e02f2835c4ff17",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:39:45.876628Z",
     "start_time": "2024-11-04T20:39:45.871632Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "695c461fbf2af29a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Differentiation in Autograd",
   "id": "cc881ea2edd0cdf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:43:38.179116Z",
     "start_time": "2024-11-04T20:43:38.175045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([2.,3.], requires_grad=True)\n",
    "b = torch.tensor([4.,5.], requires_grad=True)"
   ],
   "id": "5c2382f2828d6931",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:43:54.195157Z",
     "start_time": "2024-11-04T20:43:54.186433Z"
    }
   },
   "cell_type": "code",
   "source": "Q = 3*a**3 - b**2",
   "id": "7f517cb289201110",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:43:55.990372Z",
     "start_time": "2024-11-04T20:43:55.985940Z"
    }
   },
   "cell_type": "code",
   "source": "Q",
   "id": "f667b44741e0819d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 56.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### The next explanations are from \"Deep Learning with PyTorch: A 60 Minute Blitz > A Gentle Introduction to torch.autograd\" tutorial.\n",
    "#### https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ],
   "id": "8fbf907cd3c2046d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "<h5>Let’s assume a and b to be parameters of an NN, and Q to be the error. In NN training, we want gradients of the error w.r.t. parameters.</h5>\n",
    "i.e --> ∂Q / ∂a = 9a^2 and ∂Q / ∂b = -2b\n",
    "<h5>When we call .backward() on Q, autograd calculates these gradients and stores them in the respective tensors’ .grad attribute.</h5>\n",
    "\n",
    "<h5>We need to explicitly pass a gradient argument in Q.backward() because it is a vector. gradient is a tensor of the same shape as Q, and it represents the gradient of Q w.r.t. itself, i.e.</h5>\n",
    "dQ / dQ = 1\n",
    "\n",
    "Equivalently, we can also aggregate Q into a scalar and call backward implicitly, like Q.sum().backward()."
   ],
   "id": "bfce06868ebd0a2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:54:17.169482Z",
     "start_time": "2024-11-04T20:54:17.138496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "external_grad = torch.tensor([1.,1.])\n",
    "Q.backward(gradient=external_grad)"
   ],
   "id": "6d364fb60ff4b034",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:54:29.725853Z",
     "start_time": "2024-11-04T20:54:29.717521Z"
    }
   },
   "cell_type": "code",
   "source": "print(9*a**2 == a.grad)",
   "id": "33f38f41759789",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:54:43.171754Z",
     "start_time": "2024-11-04T20:54:43.166486Z"
    }
   },
   "cell_type": "code",
   "source": "print(-2*b == b.grad)",
   "id": "2912e6acab7cfc7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:00:10.530873Z",
     "start_time": "2024-11-04T21:00:10.392077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "id": "355f30b4297bab7f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:01:15.612929Z",
     "start_time": "2024-11-04T21:01:15.603326Z"
    }
   },
   "cell_type": "code",
   "source": "model.fc = nn.Linear(512, 10)",
   "id": "e785febf6939176d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:01:59.599664Z",
     "start_time": "2024-11-04T21:01:59.594626Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)",
   "id": "3b483944b2d15aff",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c8b913b2eb33acb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
